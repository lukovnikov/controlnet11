{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce9180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91acffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634abf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unflatten_elem_subf(x, f=None, numargs=1):\n",
    "    args, rest = x[:numargs], x[numargs:]\n",
    "    ret = f(args)\n",
    "    return ret, rest\n",
    "    \n",
    "    \n",
    "def flatten_inputs(inputs):\n",
    "    if isinstance(inputs, torch.Tensor):\n",
    "        return [inputs], lambda x: x[0]\n",
    "    elif isinstance(inputs, (list, tuple)):\n",
    "        istuple = isinstance(inputs, tuple)\n",
    "        flat_out = []\n",
    "        unflatten_elem_fs = []\n",
    "        for elem in inputs:\n",
    "            flat_elem, unflatten_elem = flatten_inputs(elem)\n",
    "            unflatten_elem_f = partial(unflatten_elem_subf, f=unflatten_elem, numargs=len(flat_elem))\n",
    "            unflatten_elem_fs.append(unflatten_elem_f)\n",
    "            flat_out += flat_elem\n",
    "        def unflatten_list(x):\n",
    "            ret = []\n",
    "            for unflatten_elem_f in unflatten_elem_fs:\n",
    "                retelem, x = unflatten_elem_f(x)\n",
    "                ret.append(retelem)\n",
    "            if istuple:\n",
    "                ret = tuple(ret)\n",
    "            return ret\n",
    "        return flat_out, unflatten_list\n",
    "    elif isinstance(inputs, dict):\n",
    "        flat_out = []\n",
    "        unflatten_elem_fs = {}\n",
    "        for k, v in inputs.items():\n",
    "            flat_elem, unflatten_elem = flatten_inputs(v)\n",
    "            unflatten_elem_f = partial(unflatten_elem_subf, f=unflatten_elem, numargs=len(flat_elem))\n",
    "            unflatten_elem_fs[k] = unflatten_elem_f\n",
    "            flat_out += flat_elem\n",
    "        def unflatten_dict(x):\n",
    "            ret = {}\n",
    "            for k, unflatten_elem_f in unflatten_elem_fs.items():\n",
    "                retelem, x = unflatten_elem_f(x)\n",
    "                ret[k] = retelem\n",
    "            return ret\n",
    "        return flat_out, unflatten_dict\n",
    "    elif hasattr(inputs, \"flatten_inputs_for_gradient_checkpoint\"):\n",
    "        return inputs.flatten_inputs_for_gradient_checkpoint()\n",
    "    else:\n",
    "        raise Exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb029b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTextConditioning():\n",
    "    def __init__(self, embs, layer_ids=None, token_ids=None, global_prompt_mask=None, global_bos_eos_mask=None):\n",
    "        \"\"\"\n",
    "        embs:       (batsize, seqlen, embdim)\n",
    "        layer_ids:  (batsize, seqlen) integers, with 0 for no-layer global tokens\n",
    "        token_ids:  (batsize, seqlen) integers for tokens from tokenizer\n",
    "        global_prompt_mask:  (batsize, seqlen) bool that is 1 where the global prompt is and 0 where the local regional prompts are\n",
    "        global_bos_eos_mask: (batsize, seqlen) bool that is 1 where the global bos and eos tokens are and 0 elsewhere\n",
    "        \"\"\"\n",
    "        self.embs = embs\n",
    "        self.device = self.embs.device\n",
    "        self.layer_ids = layer_ids\n",
    "        self.token_ids = token_ids\n",
    "        self.global_prompt_mask = global_prompt_mask\n",
    "        self.global_bos_eos_mask = global_bos_eos_mask\n",
    "        self.cross_attn_masks = None\n",
    "        self.progress = None\n",
    "        self.strength = 10\n",
    "        self.threshold = None\n",
    "        self.softness = 0.2\n",
    "        self.controlonly = False\n",
    "        self.controlledonly = False\n",
    "        \n",
    "    def cross_attention_control(self, sim, numheads=1):\n",
    "        \"\"\" Takes the unscaled unnormalized attention scores computed by cross-attention module, returns adapted attention scores. \"\"\"\n",
    "        wf = self.weight_func(sim)\n",
    "        \n",
    "        wf = wf[:, None].repeat(1, numheads, 1, 1)\n",
    "        wf = wf.view(-1, wf.shape[-2], wf.shape[-1])\n",
    "        \n",
    "        sim = sim + wf\n",
    "        return sim\n",
    "    \n",
    "    def weight_func(self, sim):\n",
    "        mask = self.cross_attn_masks[sim.shape[1]].to(sim.dtype)\n",
    "        ret = mask * sim.std() * self.strength\n",
    "        return ret\n",
    "    \n",
    "    def flatten_inputs_for_gradient_checkpoint(self):\n",
    "        flat_out = [self.embs]\n",
    "        def recon_f(x:list):\n",
    "            self.embs = x[0]\n",
    "            return self\n",
    "        return flat_out, recon_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a594953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.CustomTextConditioning object at 0x7fb1b71da640>, {'b': [[tensor([2])]]}, [tensor([3]), tensor([4]), tensor([5]), [tensor([6]), tensor([7])]], {'a': tensor([8])}]\n"
     ]
    }
   ],
   "source": [
    "x = [CustomTextConditioning(torch.tensor([1.00])), {\"b\": [[torch.tensor([2])]]}, [torch.tensor([3]), torch.tensor([4]), torch.tensor([5]), [torch.tensor([6]), torch.tensor([7])]], {\"a\": torch.tensor([8])}]\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb3d7e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.]),\n",
       " tensor([2]),\n",
       " tensor([3]),\n",
       " tensor([4]),\n",
       " tensor([5]),\n",
       " tensor([6]),\n",
       " tensor([7]),\n",
       " tensor([8])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_x, unflatten_x = flatten_inputs(x)\n",
    "flat_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "889ca259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.CustomTextConditioning at 0x7fb1b71da640>,\n",
       " {'b': [[tensor([2])]]},\n",
       " [tensor([3]), tensor([4]), tensor([5]), [tensor([6]), tensor([7])]],\n",
       " {'a': tensor([8])}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unflatten_x(flat_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efcc20df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.CustomTextConditioning at 0x7fb1b71da640>,\n",
       " {'b': [[tensor([2])]]},\n",
       " [tensor([3]), tensor([4]), tensor([5]), [tensor([6]), tensor([7])]],\n",
       " {'a': tensor([8])}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f14d6353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d68dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (torch.zeros(5,3), torch.ones(5))\n",
    "flat_x, unflatten_x = flatten_inputs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "853dde29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " tensor([1., 1., 1., 1., 1.])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a9a44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " tensor([1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unflatten_x(flat_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e574fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ControlNetV11",
   "language": "python",
   "name": "control-v11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
